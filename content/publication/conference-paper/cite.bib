@inproceedings{chauhan2023powrl,
  title={PowRL: A reinforcement learning framework for robust management of power networks},
  author={Chauhan, Anandsingh and Baranwal, Mayank and Basumatary, Ansuma},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={14757--14764},
  year={2023}}


@inproceedings{10.1145/3632410.3632426,
author = {Shelke, Omkar and Pathakota, Pranavi and Chauhan, Anandsingh and Meisheri, Hardik and Khadilkar, Harshad and Ravindran, Balaraman},
title = {A Learning Approach for Discovering Cost-Efficient Integrated Sourcing and Routing Strategies in E-Commerce},
year = {2024},
isbn = {9798400716348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632410.3632426},
doi = {10.1145/3632410.3632426},
abstract = {This paper presents an integrated algorithmic framework for minimising product delivery costs in e-commerce (known as the cost-to-serve or CTS). One of the major challenges plaguing is the large volume of dynamically generated orders from multiple customers, each of which has to be fulfilled from one of several warehouses using a fleet of vehicles. This results in two levels of decision-making: selection of a fulfillment node for each order (including the option of deferral to a future time), followed by routing of vehicles (each of which can carry multiple orders originating from the same warehouse). To handle this, we propose an approach that combines graph neural networks, reinforcement learning, and an existing vehicle routing heuristic. We include real-world constraints such as warehouse inventory capacity, vehicle characteristics such as travel times, service times, carrying capacity, and customer constraints including time windows for delivery. The complexity of this problem arises from the fact that outcomes (rewards) are driven both by the fulfillment node mapping as well as the routing algorithms, and are spatio-temporally distributed. The problem is formulated as a Markov Decision Process (MDP) and solved by using a Graph Auto Encoder (GAE) in combination with Deep Q-Learning for fulfillment node mapping. Our experiments show that this algorithmic pipeline outperforms pure heuristic policies.},
booktitle = {Proceedings of the 7th Joint International Conference on Data Science \& Management of Data (11th ACM IKDD CODS and 29th COMAD)},
pages = {430â€“438},
numpages = {9},
keywords = {Cost to Serve, E-commerce, Fulfillment Node Selection, Graph Neural Networks, Reinforcement Learning},
location = {Bangalore, India},
series = {CODS-COMAD '24}}


@misc{shelke2023multiagentlearningefficientfulfilment,
      title={Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in E-Commerce}, 
      author={Omkar Shelke and Pranavi Pathakota and Anandsingh Chauhan and Harshad Khadilkar and Hardik Meisheri and Balaraman Ravindran},
      year={2023},
      eprint={2311.16171},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.16171}, 
}
